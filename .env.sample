
REDIS_BULL_DB=redis://127.0.0.1:6379

# Bull redis queue name that receives the events jobs
REDIS_BULL_EVENTS_QUEUNAME="event-track"

# Clickhouse db that gonna receive the events,
#  where tables will be created and filled with your events:
DESTINATION_CLICKHOUSE_DB="http://localhost:8123"
DESTINATION_CLICKHOUSE_DB_NAME=events_bull

# Redis `job.data` property used to specify the type of the event 
#  (be aware that the type of the event is the Clickhouse table name)
# By default, this property is `event_type`: 
# The possible values for this key are: 
#  "clickhouse_table", "event_type", "__event_type"
#
# Example of a `job.data` single enqueued event payload:
#  { 
#     "event_type": "<event_clickhouse_table_name>", 
#     ...Rest of the column-values of the event
#  }
REDIS_JOB_EVENT_TYPE_PROPERTY="event_type"

# Repeat interval for the push of the events to the Clickhouse tables
BULK_REPEAT_INTERVAL_SEC=5

# Maximum number of events we gonna INSERT into the according destination table, 
#  on each repeat interval.
TAKE_UP_TO_PER_BATCH=100

# Use Clickhouse async_insert + wait_for_async_insert 
# https://clickhouse.com/docs/optimize/asynchronous-inserts#enabling-asynchronous-inserts
USE_CLICKHOUSE_ASYNC_INSERT=1

# Set to 1 if you want the new columns on existing tables are set to NULL (Nullable) or not
CLICKHOUSE_NEW_COL_NULLABLE=0